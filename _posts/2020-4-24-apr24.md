---
layout: post
title:  "LeetCode 146. LRU Cache (April Challenge Day #24)" 
categories: [April Challenge]
---
## Description:
Design and implement a data structure for `Least Recently Used (LRU) cache`. It should support the following operations: `get` and `put`.

`get(key)` - Get the value (will always be positive) of the key if the key exists in the cache, otherwise return -1.

`put(key, value)` - Set or insert the value if the key is not already present. When the cache reached its capacity, it should invalidate the least recently used item before inserting a new item.

The cache is initialized with a `positive` capacity.

Follow up:
Could you do both operations in **O(1)** time complexity?

## Example:
```python
cache = LRUCache( 2 )

cache.put(1, 1)
cache.put(2, 2)
cache.get(1)       # returns 1
cache.put(3, 3)    # evicts key 2
cache.get(2)       # returns -1 (not found)
cache.put(4, 4)    # evicts key 1
cache.get(1)       # returns -1 (not found)
cache.get(3)       # returns 3
cache.get(4)       # returns 4
```

## Solution Explanation:
Because both `get` and `put` function need `O(1)` time complexity, which means it must utilize HashMap so that lookup can be done in `O(1)`. However, in order to bring in the order of elements, you have to think of a way to sort the elements so that the least used element can be easily accessed in `O(1)`. Speaking of moving elements around within `O(1)`, also insert and delete element in `O(1)`, **Linked List** is your must-have tool. 

So the basic idea will be, keep track of a HashMap to store `key` as its key and `ListNode(key, value)` as its value so that you can get its value by looking up `HashMap[key].value`. And also the values of HashMap should be in order so that when the size limit is reached, you can easily get rid of the head (or tail) of the **Linked List** and insert in new **ListNode**. 

## Solution:

```python
class ListNode:
    def __init__(self, key, value, prev=None, next=None):
        self.key = key
        self.value = value
        self.prev = prev
        self.next = next

class LRUCache:

    def _move_to_tail(self, node):
        self._remove_from_cache(node)
        self._add_to_tail(node)
        
        
    def _add_to_tail(self, node):
        node.prev = self.tail.prev
        node.next = self.tail
        self.tail.prev.next = node
        self.tail.prev = node
        self.size += 1
        
    
    def _remove_from_cache(self, node):
        node.prev.next = node.next
        node.next.prev = node.prev
        self.size -= 1
        
    def _pop_head(self):
        node = self.head.next
        self._remove_from_cache(node)
        return node.key
        
        
    def __init__(self, capacity: int):
        self.vals = {}
        self.head = ListNode(0,0)
        self.tail = ListNode(0,0,prev=self.head)
        self.head.next = self.tail
        self.capacity = capacity
        self.size = 0

    def get(self, key: int) -> int:
        node = self.vals.get(key, None)
        if not node:
            return -1
        else:
            self._move_to_tail(node)
            return node.value


    def put(self, key: int, value: int) -> None:
        if key in self.vals:
            self._remove_from_cache(self.vals[key])
            del self.vals[key]

        node = ListNode(key, value)
        self.vals[key] = node
        self._add_to_tail(node)
        
        if self.size > self.capacity:
            head_key = self._pop_head()
            del self.vals[head_key]

```
